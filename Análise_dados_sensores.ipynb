{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarcisiolucas/Analise-dados-sensores/blob/main/An%C3%A1lise_dados_sensores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo para análise de dados de sensores"
      ],
      "metadata": {
        "id": "XrGtDT25p62C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa parte inicial do notebook tem como objetivo demonstrar um **modelo de análise de dados de um sensor**, abrangendo os principais requisitos para o entendimento e abstração de informações com base nos dados. Sendo os requisitos:\n",
        "\n",
        "\n",
        "1. Avaliação e inclusão das bibliotecas necessárias para realizar as operações\n",
        "2.   Leitura do arquivo disponibilizado pela Datalog\n",
        "3.   Permitir filtrar ou realizar um resample dos dados \n",
        "4. Separação dos dados necessários para essa análise (dois ou mais?)\n",
        "5. Realizar uma visualização interativa dos dados filtrados ou até mesmo deles brutos\n",
        "6. Permitir operações (soma, integração e derivação) entre graficos distintos de mais de um dado\n",
        "\n",
        "Após a definição do modelo, serão criadas novas seções **nesse mesmo caderno** que utilizam ele como base para analisar os dados de um ou mais sensores\n",
        "\n",
        "### Sugestões:\n",
        "* Estude pipelines para facilitar o tratamento dos dados\n",
        "* Não economize elementos gráficos para melhorar a visualização de seus dados\n",
        "* Seus dados precisam contar uma história e provar algo (Ex. testes de sensores provam que o sensor é confiável. Seus dados devem mostrar isso)\n",
        "* Certifique-se da origem do seu dados. Lembre-se do GIGO (Garbage In, Garbage Out). Não adianta ter um modelo eficiente se os dados não foram aquisitados da forma correta\n",
        "* Sempre pesquise novas bibliotecas e frameworks na área de Data Science\n",
        "* Crie uma conta no Kaggle. Existem milhares de projetos nos quais você pode se inspirar para otimizar seu modelo. No YouTube existem vários projetos também, muitos deles criados na hora em formato de curso"
      ],
      "metadata": {
        "id": "H8sq68kQqM4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Avaliação e inclusão das bibliotecas necessárias para realizar as operações\n",
        "\n",
        "Como as operações serão majoritariamente realizadas utilizando leitura de arquivos e plot de gráficos utilizaremos as seguintes bibliotecas:\n",
        "\n",
        "*   **pandas** - operações com dataframes\n",
        "*   **matplotlib** - visualização gráfica dos dados\n",
        "*   **seaborn** - estatística e visualização gráfica mais otimizada. É baseada no matplotlib\n",
        "*   **plotly** - plotar gráficos interativos\n",
        "* **numpy** - Cálculo dos gráficos"
      ],
      "metadata": {
        "id": "S_Vdx2iVuOJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import plotly.graph_objs as go"
      ],
      "metadata": {
        "id": "YMpEpq4YvId1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Leitura e resumo do arquivo disponibilizado pela Datalog\n",
        "\n",
        "### Para realizar a leitura, primeiramente é necessário um repositório no GitHub contendo o arquivo.\n",
        "\n",
        "###-> Para incluir i dataset a partir do repositório no Github:\n",
        "\n",
        "* Entre no repositório\n",
        "\n",
        "https://github.com/caiussouza/Controls-Data-Analysis\n",
        "* Clique no arquivo a ser lido. No exemplo, é o \"primeira_analise.csv\"\n",
        "* Clique em \"Raw\" e copie a url. No exemplo, é\n",
        "\n",
        "https://raw.githubusercontent.com/caiussouza/Controls-Data-Analysis/main/primeira_analise.csv\n",
        "* Utilize o método .read_csv('INSIRA URL')\n",
        "\n",
        "*nota: O arquivo disponibilizado pela datalog utiliza tabulação como metodo de separação dos intens e não espaço como aparenta e nem vírgula que é o padrão de arquivos csv, portanto na hora de realizar a leitura passar `sep = '\\t'` como parâmetro*"
      ],
      "metadata": {
        "id": "mEAOcSNrsuOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_dataframe = 'https://raw.githubusercontent.com/tarcisiolucas/Analise-dados-sensores/main/09_30_Test_Data/ARQ19.txt'\n",
        "teste = pd.read_csv(url_dataframe, sep='\\t')"
      ],
      "metadata": {
        "id": "yV0G_Mibx5oV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualizando o resumo do dataset\n",
        "\n",
        "Exemplos:\n",
        "\n",
        "*   **teste.info()** - exibe informações sobre o dataframe, incluindo o número de linhas e colunas, nomes e tipos de dados das colunas e o uso de memória.\n",
        "*   **teste.head()** - exibe as 5 primeiras linhas\n",
        "*   **teste.describe()** - exibe informações estatísticas sobre o dataframe, como médias, desvios padrões"
      ],
      "metadata": {
        "id": "YaPiw1yC35wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teste.info()"
      ],
      "metadata": {
        "id": "PS74blL-39l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste.head()"
      ],
      "metadata": {
        "id": "5JPGxyRU39c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste.describe()"
      ],
      "metadata": {
        "id": "ydUTh1Wn39Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Permitir filtrar ou realizar um resample dos dados\n",
        "\n"
      ],
      "metadata": {
        "id": "xG6A4t4lRBMt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QACgfr4Vlhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Separação dos dados necessários para essa análise\n",
        "\n",
        "Agora que os dados provavelmente já estão filtrados, vamos separar os que serão estudados do volume imenso distribuído pela datalogger. Para isso criaremos uma variavel que recebe os dados que queremos e iremos definir o tempo como índice"
      ],
      "metadata": {
        "id": "ZKKXf5o9Ceqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#troque o 'data_1' 'data_2' ou 'data_3' para o dado a ser estudado,\n",
        "#também podem ser adicionados mais dados caso necessário\n",
        "\n",
        "data_1 = 'ACCEL_X'\n",
        "data_2 = 'ACCEL_Y'\n",
        "data_3 = 'ACCEL_Z'\n",
        "\n",
        "data_analisys = teste[['TIMER', data_1, data_2, data_3]]\n",
        "data_analisys.set_index('TIMER')"
      ],
      "metadata": {
        "id": "67MudAcnEkI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como os dados analisados tem um offset de 10000 e valor dado em g, iremos subtrair o valor do offset e converter para m/s\n",
        "\n",
        "**Avalie sempre que necessário o dado a ser estudado para verificar a necessidade de conversão**"
      ],
      "metadata": {
        "id": "MXOFB0XLF9Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = 9.8\n",
        "data_analisys_converted = pd.DataFrame()\n",
        "data_analisys_converted[[data_1,data_2,data_3]] = data_analisys[[data_1, data_2, data_3]].apply(lambda x: (x - 10000)*(g/1000))"
      ],
      "metadata": {
        "id": "VlQ1aePLGTS2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Visualização interativa dos dados filtrados ou brutos\n",
        "\n",
        "Com os dados em mãos, agora iremos gerar gráficos de suas alterações em função do tempo. O meio utilizado é a biblioteca plotly"
      ],
      "metadata": {
        "id": "L-Ej6uMBG4g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declarando o eixo x como o índice da tabela (definimos anteriormente como TIMER)\n",
        "x = data_analisys.TIMER\n",
        "\n",
        "y_in_data_1 = data_analisys_converted.ACCEL_X\n",
        "y_in_data_2 = data_analisys_converted.ACCEL_Y\n",
        "y_in_data_3 = data_analisys_converted.ACCEL_Z\n",
        "\n",
        "# Criar os traços do gráfico\n",
        "trace1 = go.Scatter(x=x, y=y_in_data_1, name='Accelerometer in x')\n",
        "trace2 = go.Scatter(x=x, y=y_in_data_2, name='Accelerometer in y')\n",
        "trace3 = go.Scatter(x=x, y=y_in_data_3, name='Accelerometer in z')\n",
        "\n",
        "# Criar a figura e configurar o layout\n",
        "fig = go.Figure(data=[trace1, trace2, trace3])\n",
        "fig.update_layout(title='Accelerometer Data',\n",
        "                  xaxis_title='Time (ms)',\n",
        "                  yaxis_title='acceleration (m/s^2)')\n",
        "\n",
        "# Exibir o gráfico interativo em um navegador da web\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "J3wo1jkxIDh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Operações (soma, integração e derivação) entre graficos distintos de mais de um dado\n",
        "\n",
        "Agora que já podemos vizualizar os dados, faremos operações com esses gráficos com o intuito de obter informações relevantes para a análise. As operações que inicialmente serão feitas são:\n",
        "\n",
        "* Derivar\n",
        "* Intergrar\n",
        "* Soma e Subtração de dois dados diferentes"
      ],
      "metadata": {
        "id": "Omlj9v64O5a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Derivar um gráfico\n",
        "\n",
        "Estamos usando a função np.gradient() do NumPy para calcular a derivada dos dados em cada uma das colunas."
      ],
      "metadata": {
        "id": "ZhHSLxD3PkFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calcular a derivada dos dados\n",
        "dydx_in_data_1 = np.gradient(y_in_data_1)\n",
        "dydx_in_data_2 = np.gradient(y_in_data_2)\n",
        "dydx_in_data_3 = np.gradient(y_in_data_3)\n",
        "\n",
        "# Criar os traços do gráfico\n",
        "trace1 = go.Scatter(x=x, y=dydx_in_data_1, name='Accelerometer in x (derivative)')\n",
        "trace2 = go.Scatter(x=x, y=dydx_in_data_2, name='Accelerometer in y (derivative)')\n",
        "trace3 = go.Scatter(x=x, y=dydx_in_data_3, name='Accelerometer in z (derivative)')\n",
        "\n",
        "# Criar a figura e configurar o layout\n",
        "fig = go.Figure(data=[trace1, trace2, trace3])\n",
        "fig.update_layout(title='Derivative of Accelerometer Data',\n",
        "                  xaxis_title='Time (ms)',\n",
        "                  yaxis_title='acceleration (m/s^2)')\n",
        "\n",
        "# Exibir o gráfico interativo em um navegador da web\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CKfpG6cmQIHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integrar um gráfico\n",
        "\n",
        "Estamos usando a função np.cumsum() do NumPy para calcular a integral dos dados em cada uma das colunas. Em seguida, estamos criando um novo gráfico com os dados integrados.\n",
        "\n",
        "*nota: aparentemente não deu muito certo. Avaliar outra forma de realizar depois*"
      ],
      "metadata": {
        "id": "3Wuwno2uQsG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calcular a integral dos dados\n",
        "integral_in_data_1 = np.cumsum(y_in_data_1) * (x[1]-x[0])\n",
        "integral_in_data_2 = np.cumsum(y_in_data_2) * (x[1]-x[0])\n",
        "integral_in_data_3 = np.cumsum(y_in_data_3) * (x[1]-x[0])\n",
        "\n",
        "# Criar os traços do gráfico\n",
        "trace1 = go.Scatter(x=x, y=integral_in_data_1, name='Accelerometer in x (integral)')\n",
        "trace2 = go.Scatter(x=x, y=integral_in_data_2, name='Accelerometer in y (integral)')\n",
        "trace3 = go.Scatter(x=x, y=integral_in_data_3, name='Accelerometer in z (integral)')\n",
        "\n",
        "# Criar a figura e configurar o layout\n",
        "fig = go.Figure(data=[trace1, trace2, trace3])\n",
        "fig.update_layout(title='Integral of Accelerometer Data',\n",
        "                  xaxis_title='Time (ms)',\n",
        "                  yaxis_title='velocity (m/s)')\n",
        "\n",
        "# Exibir o gráfico interativo em um navegador da web\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "E9Tn-rUnQ37b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Soma e subtração\n",
        "\n",
        "aqui será somado e subtraído dois dados apenas como exemplo."
      ],
      "metadata": {
        "id": "F3rQu972RuEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_in_data_1 = data_analisys_converted.ACCEL_X\n",
        "y_in_data_2 = data_analisys_converted.ACCEL_Y\n",
        "\n",
        "sum_data = y_in_data_1 + y_in_data_2\n",
        "sub_data = y_in_data_1 - y_in_data_2\n",
        "\n",
        "# Criar os traços do gráfico\n",
        "trace1 = go.Scatter(x=x, y=sum_data, name='Sum data_1 + data_2')\n",
        "trace2 = go.Scatter(x=x, y=sub_data, name='Sub data_1 - data_2')\n",
        "\n",
        "# Criar a figura e configurar o layout\n",
        "fig = go.Figure(data=[trace1, trace2])\n",
        "fig.update_layout(title='Accelerometer Data',\n",
        "                  xaxis_title='Time (ms)',\n",
        "                  yaxis_title='acceleration (m/s^2)')\n",
        "\n",
        "# Exibir o gráfico interativo em um navegador da web\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "3NBHjgf3SCO_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}